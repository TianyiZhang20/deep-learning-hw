{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda\\envs\\py311\\Lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] 找不到指定的程序。'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "training_data = datasets.MNIST(\n",
    "    root = './data/',\n",
    "    train = True,                         \n",
    "    transform = ToTensor()\n",
    ")\n",
    "test_data = datasets.MNIST(\n",
    "    root = './data/', \n",
    "    train = False, \n",
    "    transform = ToTensor()\n",
    ")\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "loaders = {\n",
    "    'train' : DataLoader(training_data,\n",
    "                         batch_size=3000,\n",
    "                         shuffle=True,\n",
    "                         num_workers=1),\n",
    "    \n",
    "    'test'  : DataLoader(test_data, \n",
    "                         batch_size=100,\n",
    "                         shuffle=True,\n",
    "                         num_workers=1),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class TinyModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(TinyModel, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(28**2, 100)\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(100, 10)\n",
    "        self.logSoftmax = torch.nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape([x.shape[0], -1])\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.logSoftmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 求解器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelSolver(object):\n",
    "    def __init__(self, model, dataloaders, **kwargs):\n",
    "        \"\"\"\n",
    "        Construct a new Solver instance.\n",
    "        ## Required arguments:\n",
    "        - model\n",
    "        - dataloaders\n",
    "\n",
    "        ## Optional arguments:\n",
    "\n",
    "        ### training details\n",
    "        - learning_rate(int): Learning rate of optimizer.\n",
    "        - num_epochs(int): The number of epochs to run for during training.\n",
    "        - weight_decay(float)\n",
    "\n",
    "        ### output\n",
    "        - print_every(int): Training losses will be printed every print_every\n",
    "          iterations.\n",
    "        - verbose(bool): Print training result or not.\n",
    "        \"\"\"\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.model = model\n",
    "        self.model = self.model.to(self.device)\n",
    "        self.dataloaders = dataloaders\n",
    "\n",
    "        # Unpack keyword arguments\n",
    "        # training stategies\n",
    "        self.learning_rate = kwargs.pop(\"learning_rate\", 1e-5)\n",
    "        self.num_epochs = kwargs.pop(\"num_epochs\", 10)\n",
    "        weight_decay = kwargs.pop(\"weight_decay\", 0.05)\n",
    "        self.optim = torch.optim.Adam(self.model.parameters(), self.learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "        # output\n",
    "        self.print_every = kwargs.pop(\"print_every\", 1)\n",
    "        self.verbose = kwargs.pop(\"verbose\", True)\n",
    "\n",
    "        # Throw an error if there are extra keyword arguments\n",
    "        if len(kwargs) > 0:\n",
    "            extra = \", \".join('\"%s\"' % k for k in list(kwargs.keys()))\n",
    "            raise ValueError(\"Unrecognized arguments %s\" % extra)\n",
    "\n",
    "        self._reset()\n",
    "\n",
    "    def _reset(self):\n",
    "        \"\"\"\n",
    "        Set up some book-keeping variables for optimization. Don't call this\n",
    "        manually.\n",
    "        \"\"\"\n",
    "        # Set up some variables for book-keeping\n",
    "        self.loss_history = []\n",
    "\n",
    "    def _step(self, batch):\n",
    "        \"\"\"\n",
    "        Make a single gradient update. This is called by train() and should not\n",
    "        be called manually.\n",
    "        \"\"\"\n",
    "        images = batch[0].to(self.device)\n",
    "        labels = batch[1].to(self.device)\n",
    "        output = self.model(images)\n",
    "        loss = self.loss(output, labels)\n",
    "        self.loss_history.append(loss.detach().cpu().numpy())\n",
    "        self.optim.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optim.step()\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Run optimization to train the model.\n",
    "        \"\"\"\n",
    "        self.model.train()\n",
    "\n",
    "        iterations_per_epoch = max(len(self.dataloaders['train']), 1)\n",
    "        num_iterations = self.num_epochs * iterations_per_epoch\n",
    "        \n",
    "        t = 0\n",
    "        for e in range(self.num_epochs):\n",
    "            # Update parameters\n",
    "            for i, batch in enumerate(self.dataloaders['train']):\n",
    "                self._step(batch)\n",
    "                # Maybe print training loss\n",
    "                if self.verbose and t % self.print_every == 0:\n",
    "                    print(\n",
    "                        \"(Training Epoch %d Iteration %d / %d) loss: %f\"\n",
    "                        % (e + 1, t + 1, num_iterations, self.loss_history[-1])\n",
    "                    )\n",
    "                t += 1\n",
    "            # Validation\n",
    "            accuracy, loss = self.val()\n",
    "            print(\"(Validation Epoch %d) loss: %f accuracy: %f\" % (e, loss, accuracy))\n",
    "\n",
    "    def val(self):\n",
    "        \"\"\"\n",
    "        Run test.\n",
    "        \"\"\"\n",
    "        accuracy_history = []\n",
    "        loss_history = []\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(self.dataloaders['test']):\n",
    "\n",
    "                images = batch[0].to(self.device)\n",
    "                labels = batch[1].to(self.device)\n",
    "                output = self.model(images)\n",
    "\n",
    "                loss_history.append(self.loss(output, labels))\n",
    "                accuracy_history.append(self.accuracy(output, labels))\n",
    "                \n",
    "        accuracy = sum(accuracy_history)/len(accuracy_history)\n",
    "        loss = sum(loss_history)/len(loss_history)\n",
    "        return accuracy, loss\n",
    "\n",
    "    def loss(self, log_prob, labels):\n",
    "        loss_function = torch.nn.NLLLoss()\n",
    "        return loss_function(log_prob, labels)\n",
    "    \n",
    "    def accuracy(self, log_prob, labels):\n",
    "        predictions = torch.argmax(log_prob, dim=-1)\n",
    "        return torch.mean((predictions == labels).to(torch.float32))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实际训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Training Epoch 1 Iteration 1 / 100) loss: 2.305859\n",
      "(Training Epoch 1 Iteration 6 / 100) loss: 2.085197\n",
      "(Training Epoch 1 Iteration 11 / 100) loss: 1.824277\n",
      "(Training Epoch 1 Iteration 16 / 100) loss: 1.554982\n",
      "(Validation Epoch 0) loss: 1.315618 accuracy: 0.790100\n",
      "(Training Epoch 2 Iteration 21 / 100) loss: 1.338567\n",
      "(Training Epoch 2 Iteration 26 / 100) loss: 1.138084\n",
      "(Training Epoch 2 Iteration 31 / 100) loss: 1.005445\n",
      "(Training Epoch 2 Iteration 36 / 100) loss: 0.877851\n",
      "(Validation Epoch 1) loss: 0.795927 accuracy: 0.848800\n",
      "(Training Epoch 3 Iteration 41 / 100) loss: 0.810048\n",
      "(Training Epoch 3 Iteration 46 / 100) loss: 0.770277\n",
      "(Training Epoch 3 Iteration 51 / 100) loss: 0.766285\n",
      "(Training Epoch 3 Iteration 56 / 100) loss: 0.718639\n",
      "(Validation Epoch 2) loss: 0.675811 accuracy: 0.875800\n",
      "(Training Epoch 4 Iteration 61 / 100) loss: 0.687512\n",
      "(Training Epoch 4 Iteration 66 / 100) loss: 0.682928\n",
      "(Training Epoch 4 Iteration 71 / 100) loss: 0.673706\n",
      "(Training Epoch 4 Iteration 76 / 100) loss: 0.662435\n",
      "(Validation Epoch 3) loss: 0.629314 accuracy: 0.884700\n",
      "(Training Epoch 5 Iteration 81 / 100) loss: 0.663938\n",
      "(Training Epoch 5 Iteration 86 / 100) loss: 0.630531\n",
      "(Training Epoch 5 Iteration 91 / 100) loss: 0.646990\n",
      "(Training Epoch 5 Iteration 96 / 100) loss: 0.636738\n",
      "(Validation Epoch 4) loss: 0.602104 accuracy: 0.887100\n"
     ]
    }
   ],
   "source": [
    "tinymodel = TinyModel()\n",
    "solver = ModelSolver(tinymodel, \n",
    "                     loaders, \n",
    "                     num_epochs=5, \n",
    "                     learning_rate=1e-3,\n",
    "                     print_every=5)\n",
    "solver.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
